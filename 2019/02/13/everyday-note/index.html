<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Mina:300,300italic,400,400italic,700,700italic|Lato:300,300italic,400,400italic,700,700italic|Indie Flower:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/uploads/favicon-32x32-xia.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/uploads/favicon-16x16-xia.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="20192019-052019-05-05">
<meta property="og:type" content="article">
<meta property="og:title" content="笔记本">
<meta property="og:url" content="http://yoursite.com/2019/02/13/everyday-note/index.html">
<meta property="og:site_name" content="Xia&#39;s Blog">
<meta property="og:description" content="20192019-052019-05-05">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/2019/02/13/everyday-note/word-word-co-occurrence-matrix.png">
<meta property="og:image" content="http://yoursite.com/2019/02/13/everyday-note/attention.JPG">
<meta property="og:image" content="http://yoursite.com/2019/02/13/everyday-note/unlinear.JPG">
<meta property="og:image" content="http://yoursite.com/2019/02/13/everyday-note/unlinear1.JPG">
<meta property="og:image" content="http://yoursite.com/2019/02/13/everyday-note/Composition.JPG">
<meta property="og:updated_time" content="2019-05-07T03:51:18.196Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="笔记本">
<meta name="twitter:description" content="20192019-052019-05-05">
<meta name="twitter:image" content="http://yoursite.com/2019/02/13/everyday-note/word-word-co-occurrence-matrix.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":20,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/02/13/everyday-note/"/>





  <title>笔记本 | Xia's Blog</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Xia's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于我
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/02/13/everyday-note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="欢乐一只虾">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/xis.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Xia's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">笔记本</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-02-13T15:01:33+08:00">
                2019-02-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/日常笔记/" itemprop="url" rel="index">
                    <span itemprop="name">日常笔记</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  2,916
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="2019"><a href="#2019" class="headerlink" title="2019"></a>2019</h1><h2 id="2019-05"><a href="#2019-05" class="headerlink" title="2019-05"></a>2019-05</h2><h3 id="2019-05-05"><a href="#2019-05-05" class="headerlink" title="2019-05-05"></a>2019-05-05</h3><a id="more"></a>
<ul>
<li>Transformer:<ul>
<li>encoder 最后一层的输出会在decoder每一层被用到。</li>
<li>multi-head attention 层是为了找出tokens之间的关系，之后的add是为了让它不要忘记自己。</li>
<li>the Dot-Product Attention for head $i$ : <script type="math/tex; mode=display">Attention(Q_i,K_i,V_i) = softmax(\frac{Q_iK_i^{T}}{\sqrt[]{d_k}})V_i</script><ul>
<li>其中：<ul>
<li>$Q_i = XW_i^Q$ ，维度为 $input\_length \times d_k$</li>
<li>$K_i = XW_i^K$ ，维度为 $input\_length \times d_k$</li>
<li>$V_i = XW_i^V$ ，维度为 $input\_length \times d_v$</li>
</ul>
</li>
<li>论文中（<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention is all your need</a>）使用$d_k=d_v=\frac{emb\_dim}{h}$</li>
<li>不同 <em>head</em> 不共享$W_i^Q$，$W_i^K$和$W_i^V$，且都是随机初始化。</li>
<li>decoder block 里有两层multi-head attention加一层feed forward，第一层attention用来找出target sequence里的关系（需要用到mask，只允许看对应token的左边的token），第二层attention结合encoder的输出（E）和decoder上一个block的输出（D）,是为了用encoder的input sequence中各个token来表示target sequence中的各个token,相应的：<ul>
<li>$Q_i = DW_i^Q$ ，维度为 $target\_length \times d_k$</li>
<li>$K_i = EW_i^K$ ，维度为 $input\_length \times d_k$</li>
<li>$V_i = EW_i^K$ ，维度为 $input\_length \times d_v$</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2019-04"><a href="#2019-04" class="headerlink" title="2019-04"></a>2019-04</h2><h3 id="2019-04-25"><a href="#2019-04-25" class="headerlink" title="2019-04-25"></a>2019-04-25</h3><blockquote>
<p>生词：</p>
<ul>
<li><strong>diverse</strong> application domains</li>
<li>propose a <strong>taxonomy</strong></li>
</ul>
</blockquote>
<h3 id="2019-04-19"><a href="#2019-04-19" class="headerlink" title="2019-04-19"></a>2019-04-19</h3><blockquote>
<p>生词：</p>
<ul>
<li><strong>granular</strong> cell</li>
<li><strong>scrutinize</strong> over the concept</li>
</ul>
</blockquote>
<ul>
<li>word2vector<ul>
<li>高频词汇采样</li>
<li>负采样: 每次只更新target词和随机几个（5-20）“negative word”对应的权重，减小计算量，加快训练过程。</li>
</ul>
</li>
</ul>
<h3 id="2019-04-17"><a href="#2019-04-17" class="headerlink" title="2019-04-17"></a>2019-04-17</h3><blockquote>
<p>生词：</p>
<ul>
<li>chronic</li>
<li>exceedingly</li>
<li>bound to be exceedingly limited</li>
</ul>
</blockquote>
<ul>
<li>三星手机添加notification提示音：<ul>
<li>在手机文件个目录里新建一个‘Media’文件夹</li>
<li>在‘Media’文件夹里新建‘Notifications’文件夹</li>
<li>在‘Notifications’里添加<code>.MP3</code>文件</li>
</ul>
</li>
</ul>
<h3 id="2019-04-15"><a href="#2019-04-15" class="headerlink" title="2019-04-15"></a>2019-04-15</h3><ul>
<li>Discriminative Model VS. Generative Model<ul>
<li>Discriminative: they model the decision boundary between the different classes, such as Logistic Regression which based on Maximum Likelihood.</li>
<li>Generative model: they model how the data was generated can be used to make classifications, such as Naive Bayes.</li>
</ul>
</li>
<li><a href="https://towardsdatascience.com/checklist-for-debugging-neural-networks-d8b2a9434f21?source=email-b01757374e14-1555187113798-digest.reader------1-58------------------811dbe59_37a4_4c19_9db6_ee6b790471a8-1&amp;sectionName=top" target="_blank" rel="noopener">Debugging Neural Networks</a><ol>
<li>Start simple:<ul>
<li>Building a simpler model first. Then gradually add model complexity.</li>
<li>Train your model on a single data point. Using 1 or 2 training data points to confirm whether model is able to overfit, which means it immediately overfit with a training accuracy of 100% and random guessing in validation phase.</li>
</ul>
</li>
<li>Confirm your loss:<ul>
<li>The loss is appropriate for the task(choosing cross-entropy loss or mean squared error?)</li>
<li>Your loss functions are being measured on the correct scale. It’s best to first check the data loss alone (so set regularization strength to zero).</li>
</ul>
</li>
<li>Check intermediate outputs and connections</li>
<li>Diagnose parameters<ul>
<li>Batch size: <ul>
<li>Small batch sizes will result in a learning process that converges quickly at the cost of noise in the training process and might lead to optimization difficulties.</li>
<li>Large-batch methods tend to converge to sharp minimizers of the training and testing functions-and as is well known, sharp minima lead to poorer generalization.</li>
</ul>
</li>
<li>Learning rate: Consider incorporating learning rate scheduling to decrease the learning rate as training progresses</li>
<li>Gradient clipping: Useful for addressing any exploding gradients.</li>
<li>Batch normalization: Fight the internal covariate shift problem.</li>
<li>Stochastic Gradient Descent (SGD): A recommended starting point is Adam or plain SGD with Nesterov momentum.</li>
<li>Regularization: </li>
<li>Dropout</li>
</ul>
</li>
<li>Track your work</li>
</ol>
</li>
</ul>
<h3 id="2019-04-11"><a href="#2019-04-11" class="headerlink" title="2019-04-11"></a>2019-04-11</h3><blockquote>
<p>生词：</p>
<ul>
<li>get accustomed to</li>
<li>take on</li>
<li>leverage</li>
<li>prominent</li>
<li>autonomy</li>
</ul>
</blockquote>
<h3 id="2019-04-09"><a href="#2019-04-09" class="headerlink" title="2019-04-09"></a>2019-04-09</h3><blockquote>
<p>生词：</p>
<ul>
<li>unary</li>
<li>sophisticated</li>
<li>prevalent</li>
<li>latent</li>
</ul>
</blockquote>
<ul>
<li>Transfer Learning:<ul>
<li>transfer learning is the process of trainibg a model on a large-scale dataset and then using that pretrained model to conduct learning for another downstream task.</li>
<li>recent work:<ul>
<li><a href="https://arxiv.org/abs/1801.06146" target="_blank" rel="noopener">ULMFit</a></li>
<li><a href="https://allennlp.org/elmo" target="_blank" rel="noopener">ELMo</a>: 2 layers of LSTM</li>
<li><a href="https://arxiv.org/abs/1806.05662" target="_blank" rel="noopener">GLoMo</a></li>
<li><a href="https://blog.openai.com/language-unsupervised/" target="_blank" rel="noopener">OpenAI transformer</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2019-04-04"><a href="#2019-04-04" class="headerlink" title="2019-04-04"></a>2019-04-04</h3><blockquote>
<p>生词：</p>
<ul>
<li>cope with</li>
<li>be composed of</li>
<li>sanitary</li>
<li>sock</li>
<li>disinfectant</li>
<li>armrest</li>
<li>fungal</li>
</ul>
</blockquote>
<h3 id="2019-04-03"><a href="#2019-04-03" class="headerlink" title="2019-04-03"></a>2019-04-03</h3><blockquote>
<p>生词：</p>
<ul>
<li>have a <strong>self-consciousness</strong></li>
<li>bungling goon</li>
<li>play is <strong>innate</strong></li>
<li>for the sake of</li>
<li><strong>befuddled</strong> aunt/uncle/parent</li>
<li><strong>enamored</strong> with face</li>
<li>recess</li>
<li>paramount</li>
<li>wane</li>
<li>sophisticate</li>
</ul>
</blockquote>
<ul>
<li>How to interact with children:<ul>
<li>Ages 0-1:<ul>
<li>attraction to faces (expressions) only grows from there</li>
<li>speak as much as possible using baby talk with infant</li>
</ul>
</li>
<li>Ages 1-3:<ul>
<li>wait for an invitation into the child’s world. Follow their verbal and nonverbal cues.</li>
</ul>
</li>
<li>Ages 3-5:<ul>
<li>don’t push child to learning school readiness and other skills.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2019-04-02"><a href="#2019-04-02" class="headerlink" title="2019-04-02"></a>2019-04-02</h3><blockquote>
<p>生词：</p>
<ul>
<li>obsessive-compulsive disorder(OCD)</li>
</ul>
</blockquote>
<h2 id="2019-03"><a href="#2019-03" class="headerlink" title="2019-03"></a>2019-03</h2><h3 id="2019-03-30"><a href="#2019-03-30" class="headerlink" title="2019-03-30"></a>2019-03-30</h3><!-- more -->
<blockquote>
<p>生词:</p>
<ul>
<li>dodge</li>
<li>legitimate</li>
<li>folk</li>
<li>profitable</li>
</ul>
</blockquote>
<h3 id="2019-03-28"><a href="#2019-03-28" class="headerlink" title="2019-03-28"></a>2019-03-28</h3><blockquote>
<p>生词：</p>
<ul>
<li>grasp</li>
<li>slang</li>
</ul>
</blockquote>
<ul>
<li><a href="https://www.tensorflow.org/tutorials/representation/word2vec" target="_blank" rel="noopener">Word2vec</a>：<ul>
<li>有两种类型<ul>
<li>连续词袋模型（CBOW）：根据上下文预测目标字词</li>
<li>Skip-Gram：根据从目标字词中预测上下文字词</li>
</ul>
</li>
<li>噪声对比估算（NCE）损失是基于逻辑回归模型进行定义的</li>
</ul>
</li>
<li><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">GloVe</a>:<ul>
<li>先从文本中处理得到一个word-word co-occurrence矩阵 <img src="/2019/02/13/everyday-note/word-word-co-occurrence-matrix.png" title="word-word co-occurrence矩阵的一个小栗子"></li>
<li>训练过程是让词向量的点乘结果尽可能等于相应两个词一起出现的概率的对数。</li>
</ul>
</li>
</ul>
<h3 id="2019-03-26"><a href="#2019-03-26" class="headerlink" title="2019-03-26"></a>2019-03-26</h3><blockquote>
<p>生词：</p>
<ul>
<li>meteor</li>
<li>splash</li>
<li>bruise</li>
<li>shatter</li>
<li>flock </li>
<li>patio</li>
<li>bureaucratic</li>
<li>unlikely</li>
<li>trickle</li>
<li>deficiency</li>
<li>patriotic</li>
</ul>
</blockquote>
<ul>
<li>vim:<ul>
<li>v: 可视模式</li>
<li>w/b：前一个单词/后一个单词</li>
<li>^：本行第一个不是blank字符的位置</li>
<li>0：本行第一个位置</li>
<li>$：本行行尾</li>
<li>g_：本行最后一个不是blank字符的位置</li>
<li>p：黏贴</li>
<li>u：undo</li>
<li>CTRL-r：redo</li>
<li>d: 删除并复制</li>
<li>y：直接复制</li>
</ul>
</li>
</ul>
<h3 id="2019-03-21"><a href="#2019-03-21" class="headerlink" title="2019-03-21"></a>2019-03-21</h3><ul>
<li>从远程Git库中下在分支到本地：<ul>
<li><code>git pull origin branch_name:local_name</code> ：获取远程库中的branch_name分支与本地的local_name分支进行merge，如果要与本地当前分支进行merge可以不写冒号和冒号后面内容，如果本地所在的当前分支（dev）与对应远程分支（origin/dev）已建立联系，只需 <code>git pull origin</code></li>
<li><code>git checkout -b local_name origin/branch_name</code>: 自动创建一个新的本地分支（local_name），并与指定远程分支关联起来。</li>
</ul>
</li>
</ul>
<h3 id="2019-03-19"><a href="#2019-03-19" class="headerlink" title="2019-03-19"></a>2019-03-19</h3><ul>
<li>支持向量机 (Support Vector Machine)：<ul>
<li>支持向量 (support vectors):<ul>
<li>support vectores are the samples that are most difficult to classify</li>
<li>they directly affect the process to find the optimum location of the decision boundaries.</li>
</ul>
</li>
<li>constrained optimization - Lagrange Multipliers<ul>
<li>obtaining extrema of function $f(x,y)$ under the constraint $g(x,y) = A$ -&gt; $f^\prime(x,y) = \lambda g^\prime(x,y)$:</li>
</ul>
</li>
</ul>
</li>
</ul>
<script type="math/tex; mode=display">\begin{split}
f^\prime (x,y) &= [f(x,y) + \lambda(A-g(x,y))]^\prime\\
 &=f^\prime(x,y) - \lambda g^\prime(x,y) = 0
\end{split} \tag{19.03.19.1}</script><ul>
<li>Math in Markdown<ul>
<li>one expression in multi-lines : \begin{split} align by ‘&amp;’ before ‘=’</li>
<li>multi-expressions in multi-lines : \begin{eqnarray*} align by ‘&amp;…&amp;’ wrap ‘=’</li>
</ul>
</li>
</ul>
<h3 id="2019-03-06"><a href="#2019-03-06" class="headerlink" title="2019-03-06"></a>2019-03-06</h3><blockquote>
<p>生词：</p>
<ul>
<li>treadmill</li>
<li>stationary</li>
<li>rack up</li>
<li>bold</li>
<li>obligation</li>
</ul>
</blockquote>
<h3 id="2019-03-05"><a href="#2019-03-05" class="headerlink" title="2019-03-05"></a>2019-03-05</h3><ul>
<li>Conda 操作：<ul>
<li>信息： <code>conda info</code></li>
<li>更新自己： <code>conda update conda</code></li>
<li>安装/更新 包：<code>conda install/update [package]</code></li>
<li>创建一个新python环境：<code>conda create --name mingzi python=3.6</code></li>
<li>激活一个python环境：<code>activate mingzi</code> (Win)/<code>source activate mingzi</code> (Linux/mac)</li>
<li>取消激活当前环境：<code>deactivate</code> (Win)/ <code>source deactivate</code> (Linux/mac)</li>
<li>环境列表：<code>conda env list</code></li>
</ul>
</li>
</ul>
<h3 id="2019-03-04"><a href="#2019-03-04" class="headerlink" title="2019-03-04"></a>2019-03-04</h3><ul>
<li>Vim 操作：<ul>
<li>dd -&gt; 删除当前行，并将这行保存到剪切板里</li>
<li>p -&gt; 粘贴剪切板里的内容</li>
<li>h，j，k，l -&gt; 移动光标（方向键也可以）</li>
<li>：help \<command> -&gt;  显示相关命令的帮助</li>
<li>u -&gt; 撤销（undo）</li>
</ul>
</li>
</ul>
<h2 id="2019-02"><a href="#2019-02" class="headerlink" title="2019-02"></a>2019-02</h2><h3 id="2019-02-28"><a href="#2019-02-28" class="headerlink" title="2019-02-28"></a>2019-02-28</h3><blockquote>
<p>生词：</p>
<ul>
<li>arithmetic</li>
</ul>
</blockquote>
<ul>
<li>Attention mechanism:<ul>
<li>attention 计算时，每个待加权部分（$y_i$）的权重只跟上下文（context）$C$ 有关，与别的部分（$y_j, j \neq i$）无关。如下图： <img src="/2019/02/13/everyday-note/attention.JPG"></li>
<li>Soft Attention vs. Hard Attention<ul>
<li>soft attention: 结果为各个待加权部分的加权和</li>
<li>hard attention：结果为根据相应概率随机选取的一个待加权部分</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="2019-02-19"><a href="#2019-02-19" class="headerlink" title="2019-02-19"></a>2019-02-19</h3><blockquote>
<p>生词：</p>
<ul>
<li>tickle</li>
<li>sibling</li>
<li>stroke a cat</li>
<li>discrepancy</li>
<li>procrastinate</li>
<li>prone</li>
</ul>
</blockquote>
<ul>
<li>scp命令：<code>scp test.txt  account@ip:/home/xxx/test.txt</code> </li>
</ul>
<h3 id="2019-02-17"><a href="#2019-02-17" class="headerlink" title="2019-02-17"></a>2019-02-17</h3><blockquote>
<p>生词：</p>
<ul>
<li>anecdote</li>
<li>instill</li>
<li>ostracism/banishment</li>
<li>squeak</li>
</ul>
</blockquote>
<ul>
<li>向量叉乘（cross product）， 如果逆时针方向相乘则结果为正，反之结果为负。叉乘的结果（三维空间）为一个向量，这个向量的大小是两个相乘的向量所构成的平行四边形的面积，方向与该平行四边形垂直。求解两个向量的叉乘可以用求解对应行列式的方法（加上一个向量 ($\hat{i},\hat{j}, \hat{k}$)）</li>
<li>线性的严格定义（Formal definition of linearity）:<ul>
<li>可加性： $L(\vec{v}+\vec{w})=L(\vec{v})+L(\vec{w})$</li>
<li>成比性：$L(c\vec{v})=cL(\vec{v})$</li>
</ul>
</li>
<li>因此，函数只要满足上面的规定也是线性的。</li>
<li>The learning your do learning forward can be substantially more efficient if you have all the right intuitions in places.</li>
</ul>
<h3 id="2019-02-15"><a href="#2019-02-15" class="headerlink" title="2019-02-15"></a>2019-02-15</h3><blockquote>
<p>生词：</p>
<ul>
<li>perusal</li>
<li>connotation</li>
<li>fumble</li>
<li>clumsily</li>
<li>intercept</li>
<li>distort</li>
<li>perception</li>
<li>clutter</li>
<li>duality</li>
</ul>
</blockquote>
<ul>
<li><code>GraphDef</code> 是TensorFlow用来保存/加载<code>Graph</code>时的中间对象。保存时，可以通过<code>Graph.as_graph_def()</code>或者<code>Session.graph_def</code>获取到<code>GraphDef</code>对象用于序列化保存到文件；加载时，也需要先用<code>tf.GraphDef()</code>获取一个空<code>GraphDef</code>对象然后用 <strong>.pb</strong> 文件中的数据来填充（<code>graph_def.ParseFromString(f.read())</code>）,最后通过<code>tf.import_graph_def(graph_def, name=&#39;prefix&#39;)</code>的形式加载到指定的Graph中。</li>
<li>对偶性： 两种数学事物之间自然而又出乎意料的对应关系</li>
</ul>
<h3 id="2019-02-14"><a href="#2019-02-14" class="headerlink" title="2019-02-14"></a>2019-02-14</h3><blockquote>
<p>生词：</p>
<ul>
<li>spouse</li>
<li>tepastry</li>
<li>gargantuan</li>
</ul>
</blockquote>
<ul>
<li><p>用 <code>tf.train.Saver()</code> 保存/载入模型：</p>
<ul>
<li><p><strong>.data</strong> 文件保存权重（weights）；<strong>.meta</strong> 文件保存计算图的各种元数据（metadata）比如学习率和优化器； <strong>.index</strong> 文件保存键-值对，用来根据模型中的tensor name在 .data 文件中找到相应的data。</p>
<ul>
<li><strong>载入图结构和元数据</strong> 用 <code>tf.train.import_meta_graph(&#39;models/model.ckpt-1000.meta&#39;)</code>, 该方法自动将 “models/model.ckpt-1000.meta” 文件中保存的图加载到默认图（default_graph）中并返回一个 <code>Saver</code>。</li>
<li><strong>回复/载入权重（weights）</strong> 的过程跟载入图结构和元数据不同的是它必须在要给 <code>Session</code> 中执行，可以把它理解为权重的初始化类似的过程，如下：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment">#用载入权重的方式来初始化权重，就不需要tf.global_variables_initializer()过程了</span></span><br><span class="line">    saver.restore(sess, <span class="string">'models/model.ckpt.data-1000-00000-of-00001'</span>)</span><br><span class="line">    print(sess.run(global_step_tensor))</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>可以声明多个 <code>Saver</code> 来保存所有或特定变量（<code>Variables</code>）并用字典({name:Var})的形式给变量指定名字：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v1 = tf.Variable(<span class="number">1.</span>, name=<span class="string">"v1"</span>)</span><br><span class="line">all_saver = tf.train.Saver()</span><br><span class="line">v1_saver = tf.train.Saver(&#123;<span class="string">"V1"</span>:v1&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li><p>一个 <code>Saver</code> 只能保存当前 <code>Session</code> 对应 <code>Graph</code> 中的变量,所以程序中有多个 <code>Graph</code> 时要注意 <code>Saver</code> 的使用，下面这样使用 <code>Saver</code> 就会报错：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    v1 = tf.Variable(<span class="number">5.</span>, dtype=tf.float32)</span><br><span class="line">print(v1.graph == g) <span class="comment"># 输出True</span></span><br><span class="line">print(v1.graph == tf.get_default_graph()) <span class="comment"># 输出False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这个Saver如果在绑定默认default_graph的Session中执行会报错，因为v1是在 g 中的变量而不是default_graph中</span></span><br><span class="line">saver = tf.train.Saver([v1])</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line"></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">    saver.save(sess, <span class="string">'./test'</span>) <span class="comment">#执行这句代码时会报错</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>用 <code>tf.saved_model.simple_save</code> 保存模型：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">simple_save(session,</span><br><span class="line">            export_dir,</span><br><span class="line">            inputs=&#123;<span class="string">"x"</span>: x, <span class="string">"y"</span>: y&#125;),</span><br><span class="line">            outputs=&#123;<span class="string">"z"</span>: z&#125;)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>.pb</strong> 文件保存图结构和元数据； <strong>variables</strong> 文件夹内保存当前的权重。</li>
<li>加载saved_model：  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export_dir = ...</span><br><span class="line">...</span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=tf.Graph()) <span class="keyword">as</span> sess:</span><br><span class="line">    tf.saved_model.loader.load(sess, [tag_constants.TRAINING], export_dir)</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>把模型的所有信息（包括图数据和权重信息）全部保存到一个 .pb 文件中：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.framework <span class="keyword">import</span> graph_util</span><br><span class="line">output_graph_def = graph_util.convert_variables_to_constants(session, </span><br><span class="line">                                                             session.graph_def,</span><br><span class="line">                                                             output_node_names=[</span><br><span class="line">                                                                         <span class="string">'model_intent/intent_scores'</span>])</span><br><span class="line"><span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'models/intent_model.pb'</span>, mode=<span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(output_graph_def.SerializeToString())</span><br></pre></td></tr></table></figure>
<p>  加载保存的 .pb 文件：</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_graph</span><span class="params">(frozen_graph_filename)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.GFile(frozen_graph_filename, <span class="string">"rb"</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()              <span class="comment"># 创建一个空的graph_def</span></span><br><span class="line">        graph_def.ParseFromString(f.read())    <span class="comment"># 用 .pb 文件中保存的对象填充该graph_def</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> graph:</span><br><span class="line">        <span class="comment"># 下面的name参数的值会作为graph中所有op的前缀</span></span><br><span class="line">        tf.import_graph_def(graph_def, name=<span class="string">"prefix"</span>)</span><br><span class="line">    <span class="keyword">return</span> graph</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2019-02-13"><a href="#2019-02-13" class="headerlink" title="2019-02-13"></a>2019-02-13</h3><ul>
<li>线性变换（Linear transformation）就是输入一个向量然后输出另一个向量。这里的transformation(变换)和function（函数）同义，之所以用transformation是因为线性代数里面的线性变换是可以在坐标系中（低维）可视化表现出来的。前面的形容词Linear的意思是：整个坐标系变换之后直线依旧是直线，原点保持固定。下面两个变换都不是线性变换(灰线表示原坐标系)。</li>
</ul>
<img src="/2019/02/13/everyday-note/unlinear.JPG"> <img src="/2019/02/13/everyday-note/unlinear1.JPG">
<ul>
<li>矩阵乘法相当于两个线性变换的复合。类似： <img src="/2019/02/13/everyday-note/Composition.JPG"></li>
<li><strong>线性变换的行列式</strong> 可以理解为线性变换后原单位面积被拉伸/压缩的倍数。 用这个概念很好理解： $det(M_1M_2)=det(M_1)det(M_2)$</li>
<li><strong>矩阵的逆</strong> 在transformation上的变现形式就是逆变换（顺时针旋转90度对应的矩阵的逆就是逆时针旋转90度对应的矩阵），因此矩阵A乘以矩阵A的逆表示变换之后又逆变换，相当于什么都没做，即：<script type="math/tex; mode=display">
A^{-1}A= \left[
  \begin{matrix}
      1 & 0\\
      0 & 1
  \end{matrix}
  \right]</script></li>
<li>矩阵（或者说线性变换）的 <strong>秩</strong>（rank）可以理解为线性变换结束后整个坐标系的维度（维度是否被压缩，或者保持原维度）。更加严谨的定义是矩阵列空间的维度（换句话说就是所有列向量可以在几维空间里表示）。所以顾名思义，<strong>满秩</strong>，表示任何两个列向量都不线性相关即秩数等于列向量的个数即达到最大值。</li>
<li>零空间（Null space），一些变换后落在零向量上的向量构成的空间。</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/08/MachineLearning-ZZH/" rel="next" title="读书笔记：《机器学习》by周志华 (阅读中...)">
                <i class="fa fa-chevron-left"></i> 读书笔记：《机器学习》by周志华 (阅读中...)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/xis.jpg"
                alt="欢乐一只虾" />
            
              <p class="site-author-name" itemprop="name">欢乐一只虾</p>
              <p class="site-description motion-element" itemprop="description">xia写的</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#2019"><span class="nav-text">2019</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2019-05"><span class="nav-text">2019-05</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-05-05"><span class="nav-text">2019-05-05</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2019-04"><span class="nav-text">2019-04</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-25"><span class="nav-text">2019-04-25</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-19"><span class="nav-text">2019-04-19</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-17"><span class="nav-text">2019-04-17</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-15"><span class="nav-text">2019-04-15</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-11"><span class="nav-text">2019-04-11</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-09"><span class="nav-text">2019-04-09</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-04"><span class="nav-text">2019-04-04</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-03"><span class="nav-text">2019-04-03</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-04-02"><span class="nav-text">2019-04-02</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2019-03"><span class="nav-text">2019-03</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-30"><span class="nav-text">2019-03-30</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-28"><span class="nav-text">2019-03-28</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-26"><span class="nav-text">2019-03-26</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-21"><span class="nav-text">2019-03-21</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-19"><span class="nav-text">2019-03-19</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-06"><span class="nav-text">2019-03-06</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-05"><span class="nav-text">2019-03-05</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-03-04"><span class="nav-text">2019-03-04</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2019-02"><span class="nav-text">2019-02</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-28"><span class="nav-text">2019-02-28</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-19"><span class="nav-text">2019-02-19</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-17"><span class="nav-text">2019-02-17</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-15"><span class="nav-text">2019-02-15</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-14"><span class="nav-text">2019-02-14</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2019-02-13"><span class="nav-text">2019-02-13</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">欢乐一只虾</span>

  
</div>









        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      你是我的第
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      位客人
    </span>
  

  
    <span class="site-pv">
      这是第
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次访问
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
